{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f89f7684",
      "metadata": {
        "id": "f89f7684"
      },
      "source": [
        "# Hands-On Pertemuan 6: Data Processing dengan Apache Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e30ce9d1",
      "metadata": {
        "id": "e30ce9d1"
      },
      "source": [
        "## Tujuan:\n",
        "- Memahami dan mempraktikkan data processing menggunakan Apache Spark.\n",
        "- Menggunakan Spark untuk operasi data yang efisien pada dataset besar.\n",
        "- Menerapkan teknik canggih dalam Spark untuk mengatasi kasus penggunaan nyata."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd5c2f90",
      "metadata": {
        "id": "cd5c2f90"
      },
      "source": [
        "### 1. Pengenalan Spark DataFrames\n",
        "Spark DataFrame menyediakan struktur data yang optimal dengan operasi yang dioptimalkan untuk pemrosesan data besar, yang sangat mirip dengan DataFrame di Pandas atau di RDBMS.\n",
        "\n",
        "- **Tugas 1**: Buat DataFrame sederhana di Spark dan eksplorasi beberapa fungsi dasar yang tersedia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0BPSBHehjQ7r",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BPSBHehjQ7r",
        "outputId": "e2095c98-81bf-4c72-eef7-cb165d6f1944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark==3.4.1 in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark==3.4.1) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark==3.4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hA7kXjd9jWQS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA7kXjd9jWQS",
        "outputId": "0d35d26d-6f0c-4cdd-b9f4-b1e44848907b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ASL_kohCjcLr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASL_kohCjcLr",
        "outputId": "08361b34-2f18-441a-abe8-89a9ed739f88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: findspark in /usr/local/lib/python3.10/dist-packages (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "986d01c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "986d01c7",
        "outputId": "ec397621-73c6-49f5-ff14-d65118b4338c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+------+\n",
            "|EmployeeName|Department|Salary|\n",
            "+------------+----------+------+\n",
            "|       James|     Sales|  3000|\n",
            "|     Michael|     Sales|  4600|\n",
            "|      Robert|     Sales|  4100|\n",
            "|       Maria|   Finance|  3000|\n",
            "+------------+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Contoh membuat DataFrame sederhana dan operasi dasar\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('HandsOnPertemuan6').getOrCreate()\n",
        "\n",
        "data = [('James', 'Sales', 3000),\n",
        "        ('Michael', 'Sales', 4600),\n",
        "        ('Robert', 'Sales', 4100),\n",
        "        ('Maria', 'Finance', 3000)]\n",
        "columns = ['EmployeeName', 'Department', 'Salary']\n",
        "\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fca66b73",
      "metadata": {
        "id": "fca66b73"
      },
      "source": [
        "### 2. Transformasi Dasar dengan DataFrames\n",
        "Pemrosesan data meliputi transformasi seperti filtering, selections, dan aggregations. Spark menyediakan cara efisien untuk melaksanakan operasi ini.\n",
        "\n",
        "- **Tugas 2**: Gunakan operasi filter, select, groupBy untuk mengekstrak informasi dari data, serta lakukan agregasi data untuk mendapatkan insight tentang dataset menggunakan perintah seperti mean, max, sum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aEsMyUEtmTQy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEsMyUEtmTQy",
        "outputId": "9afb5654-8d8e-46db-a179-fb18772e3839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tabel Nama Pegawai dan Salary\n",
            "+------------+------+\n",
            "|EmployeeName|Salary|\n",
            "+------------+------+\n",
            "|       James|  3000|\n",
            "|     Michael|  4600|\n",
            "|      Robert|  4100|\n",
            "|       Maria|  3000|\n",
            "+------------+------+\n",
            "\n",
            "Pegawai dengan Salary lebih dari 3000\n",
            "+------------+----------+------+\n",
            "|EmployeeName|Department|Salary|\n",
            "+------------+----------+------+\n",
            "|     Michael|     Sales|  4600|\n",
            "|      Robert|     Sales|  4100|\n",
            "+------------+----------+------+\n",
            "\n",
            "Rata-rata Salary tiap Departemen\n",
            "+----------+-----------+\n",
            "|Department|avg(Salary)|\n",
            "+----------+-----------+\n",
            "|     Sales|     3900.0|\n",
            "|   Finance|     3000.0|\n",
            "+----------+-----------+\n",
            "\n",
            "Insight Dataset\n",
            "+----------+--------------+----------+----------+------------+\n",
            "|Department|Average Salary|Max Salary|Min Salary|Total Salary|\n",
            "+----------+--------------+----------+----------+------------+\n",
            "|     Sales|        3900.0|      4600|      3000|       11700|\n",
            "|   Finance|        3000.0|      3000|      3000|        3000|\n",
            "+----------+--------------+----------+----------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Contoh operasi transformasi DataFrame\n",
        "from pyspark.sql.functions import mean, max, sum, min\n",
        "\n",
        "print (\"Tabel Nama Pegawai dan Salary\")\n",
        "df_select = df.select('EmployeeName', 'Salary')\n",
        "df_select.show()\n",
        "\n",
        "print (\"Pegawai dengan Salary lebih dari 3000\")\n",
        "df_filter = df.filter(df['Salary'] > 3000)\n",
        "df_filter.show()\n",
        "\n",
        "print (\"Rata-rata Salary tiap Departemen\")\n",
        "df_groupBy = df.groupBy('Department').avg('Salary')\n",
        "df_groupBy.show()\n",
        "\n",
        "print (\"Insight Dataset\")\n",
        "agregasi_df = df.groupBy(\"Department\").agg(\n",
        "    mean(\"Salary\").alias(\"Average Salary\"),\n",
        "    max(\"Salary\").alias(\"Max Salary\"),\n",
        "    min(\"Salary\").alias(\"Min Salary\"),\n",
        "    sum(\"Salary\").alias(\"Total Salary\")\n",
        ")\n",
        "agregasi_df.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89763d36",
      "metadata": {
        "id": "89763d36"
      },
      "source": [
        "### 3. Bekerja dengan Tipe Data Kompleks\n",
        "Spark mendukung tipe data yang kompleks seperti maps, arrays, dan structs yang memungkinkan operasi yang lebih kompleks pada dataset yang kompleks.\n",
        "\n",
        "- **Tugas 3**: Eksplorasi bagaimana mengolah tipe data kompleks dalam Spark DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14701d79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14701d79",
        "outputId": "b4d6abfc-7708-4ddf-97d0-42fba4b9490e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Salary Bonus\n",
            "+------------+----------+------+-----------+\n",
            "|EmployeeName|Department|Salary|SalaryBonus|\n",
            "+------------+----------+------+-----------+\n",
            "|       James|     Sales|  3000|      300.0|\n",
            "|     Michael|     Sales|  4600|      460.0|\n",
            "|      Robert|     Sales|  4100|      410.0|\n",
            "|       Maria|   Finance|  3000|      300.0|\n",
            "+------------+----------+------+-----------+\n",
            "\n",
            "Compensation\n",
            "+------------+----------+------+-----------+-----------------+\n",
            "|EmployeeName|Department|Salary|SalaryBonus|TotalCompensation|\n",
            "+------------+----------+------+-----------+-----------------+\n",
            "|       James|     Sales|  3000|      300.0|           3300.0|\n",
            "|     Michael|     Sales|  4600|      460.0|           5060.0|\n",
            "|      Robert|     Sales|  4100|      410.0|           4510.0|\n",
            "|       Maria|   Finance|  3000|      300.0|           3300.0|\n",
            "+------------+----------+------+-----------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Contoh manipulasi tipe data kompleks\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "print (\"Salary Bonus\")\n",
        "df_bonus = df.withColumn('SalaryBonus', df['Salary'] * 0.1)\n",
        "df_bonus.show()\n",
        "\n",
        "print (\"Compensation\")\n",
        "df_compensation = df_bonus.withColumn('TotalCompensation', col('Salary') + col('SalaryBonus'))\n",
        "df_compensation.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b3b58dd",
      "metadata": {
        "id": "5b3b58dd"
      },
      "source": [
        "### 4. Operasi Data Lanjutan\n",
        "Menggunakan Spark untuk operasi lanjutan seperti window functions, user-defined functions (UDFs), dan mengoptimalkan query.\n",
        "\n",
        "- **Tugas 4**: Implementasikan window function untuk menghitung running totals atau rangkings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "035312eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "035312eb",
        "outputId": "e49f77a0-97bc-4e6c-c23d-3430f73f2a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+------+----+\n",
            "|EmployeeName|Department|Salary|Rank|\n",
            "+------------+----------+------+----+\n",
            "|       Maria|   Finance|  3000|   1|\n",
            "|       James|     Sales|  3000|   1|\n",
            "|      Robert|     Sales|  4100|   2|\n",
            "|     Michael|     Sales|  4600|   3|\n",
            "+------------+----------+------+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Contoh menggunakan window functions\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "windowSpec = Window.partitionBy('Department').orderBy('Salary')\n",
        "df.withColumn('Rank', F.rank().over(windowSpec)).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8a097ec",
      "metadata": {
        "id": "f8a097ec"
      },
      "source": [
        "### 5. Kesimpulan dan Eksplorasi Lebih Lanjut\n",
        "Review apa yang telah dipelajari tentang pemrosesan data menggunakan Spark dan eksplorasi teknik lebih lanjut untuk mengoptimalkan pemrosesan data Anda.\n",
        "- **Tugas 5**: Buat ringkasan dari semua operasi yang telah dilakukan dan bagaimana teknik ini dapat diterapkan pada proyek data Anda."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = \"Salary_dataset.csv\"\n",
        "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
        "\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rHGa3bSqNMO",
        "outputId": "0b9701c4-a8d6-4004-e127-18354d242ec8"
      },
      "id": "3rHGa3bSqNMO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- YearsExperience: double (nullable = true)\n",
            " |-- Salary: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkfVmiT7qv8F",
        "outputId": "9c179374-aad8-4e69-c4c8-09564bf69f4e"
      },
      "id": "KkfVmiT7qv8F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------+-------+\n",
            "|_c0|   YearsExperience| Salary|\n",
            "+---+------------------+-------+\n",
            "|  0|1.2000000000000002|39344.0|\n",
            "|  1|1.4000000000000001|46206.0|\n",
            "|  2|               1.6|37732.0|\n",
            "|  3|               2.1|43526.0|\n",
            "|  4|2.3000000000000003|39892.0|\n",
            "|  5|               3.0|56643.0|\n",
            "|  6|               3.1|60151.0|\n",
            "|  7|3.3000000000000003|54446.0|\n",
            "|  8|3.3000000000000003|64446.0|\n",
            "|  9|3.8000000000000003|57190.0|\n",
            "| 10|               4.0|63219.0|\n",
            "| 11|               4.1|55795.0|\n",
            "| 12|               4.1|56958.0|\n",
            "| 13| 4.199999999999999|57082.0|\n",
            "| 14|               4.6|61112.0|\n",
            "| 15|               5.0|67939.0|\n",
            "| 16| 5.199999999999999|66030.0|\n",
            "| 17|5.3999999999999995|83089.0|\n",
            "| 18|               6.0|81364.0|\n",
            "| 19|               6.1|93941.0|\n",
            "+---+------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_RasioGajiPerTahun = df.withColumn(\"Rasio Gaji Per Tahun\", col(\"Salary\") / col(\"YearsExperience\"))\n",
        "df_RasioGajiPerTahun.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZrH1Y6vq4YF",
        "outputId": "0adaf9f6-0419-467f-bcc1-c1defea45333"
      },
      "id": "WZrH1Y6vq4YF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------+-------+--------------------+\n",
            "|_c0|   YearsExperience| Salary|Rasio Gaji Per Tahun|\n",
            "+---+------------------+-------+--------------------+\n",
            "|  0|1.2000000000000002|39344.0|  32786.666666666664|\n",
            "|  1|1.4000000000000001|46206.0|   33004.28571428571|\n",
            "|  2|               1.6|37732.0|             23582.5|\n",
            "|  3|               2.1|43526.0|  20726.666666666664|\n",
            "|  4|2.3000000000000003|39892.0|  17344.347826086956|\n",
            "|  5|               3.0|56643.0|             18881.0|\n",
            "|  6|               3.1|60151.0|  19403.548387096773|\n",
            "|  7|3.3000000000000003|54446.0|  16498.787878787876|\n",
            "|  8|3.3000000000000003|64446.0|  19529.090909090908|\n",
            "|  9|3.8000000000000003|57190.0|  15049.999999999998|\n",
            "| 10|               4.0|63219.0|            15804.75|\n",
            "| 11|               4.1|55795.0|  13608.536585365855|\n",
            "| 12|               4.1|56958.0|  13892.195121951221|\n",
            "| 13| 4.199999999999999|57082.0|  13590.952380952383|\n",
            "| 14|               4.6|61112.0|  13285.217391304348|\n",
            "| 15|               5.0|67939.0|             13587.8|\n",
            "| 16| 5.199999999999999|66030.0|  12698.076923076926|\n",
            "| 17|5.3999999999999995|83089.0|  15386.851851851854|\n",
            "| 18|               6.0|81364.0|  13560.666666666666|\n",
            "| 19|               6.1|93941.0|  15400.163934426231|\n",
            "+---+------------------+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_experience_5 = df.filter(col(\"YearsExperience\") > 5).count()\n",
        "print(f\"Jumlah orang dengan lebih dari 5 tahun pengalaman: {count_experience_5}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT925hNzsaR7",
        "outputId": "6797c2ca-18cf-422b-879c-73aff3bb9e52"
      },
      "id": "UT925hNzsaR7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah orang dengan lebih dari 5 tahun pengalaman: 14\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}