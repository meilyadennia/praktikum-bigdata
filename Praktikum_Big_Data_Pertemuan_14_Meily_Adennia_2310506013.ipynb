{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e2a030e3",
      "metadata": {
        "id": "e2a030e3"
      },
      "source": [
        "# Hands-On Pertemuan 14: Advanced Machine Learning using Spark MLlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "099562db",
      "metadata": {
        "id": "099562db"
      },
      "source": [
        "## Objectives:\n",
        "- Understand and implement advanced machine learning tasks using Spark MLlib.\n",
        "- Build and evaluate models using real-world datasets.\n",
        "- Explore techniques like feature engineering and hyperparameter tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77df771a",
      "metadata": {
        "id": "77df771a"
      },
      "source": [
        "## Introduction to Spark MLlib\n",
        "Spark MLlib is a scalable library for machine learning that integrates seamlessly with the Spark ecosystem. It supports a wide range of tasks, including regression, classification, clustering, and collaborative filtering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9ae225b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9ae225b",
        "outputId": "0491d23c-fd79-416d-ea77-4383a574b729"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [0.9999999999999992]\n",
            "Intercept: 15.000000000000009\n"
          ]
        }
      ],
      "source": [
        "# Example: Linear Regression with Spark MLlib\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName('MLlib Example').getOrCreate()\n",
        "\n",
        "# Load sample data\n",
        "data = [(1, 5.0, 20.0), (2, 10.0, 25.0), (3, 15.0, 30.0), (4, 20.0, 35.0)]\n",
        "columns = ['ID', 'Feature', 'Target']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Prepare data for modeling\n",
        "assembler = VectorAssembler(inputCols=['Feature'], outputCol='Features')\n",
        "df_transformed = assembler.transform(df)\n",
        "\n",
        "# Train a linear regression model\n",
        "lr = LinearRegression(featuresCol='Features', labelCol='Target')\n",
        "model = lr.fit(df_transformed)\n",
        "\n",
        "# Print model coefficients\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Example dataset - convert Features to Vectors\n",
        "data = [(1, Vectors.dense([2.0, 3.0]), 0), (2, Vectors.dense([1.0, 5.0]), 1),\n",
        "        (3, Vectors.dense([2.5, 4.5]), 1), (4, Vectors.dense([3.0, 6.0]), 0)]\n",
        "columns = ['ID', 'Features', 'Label']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Train logistic regression model\n",
        "lr = LogisticRegression(featuresCol='Features', labelCol='Label')\n",
        "model = lr.fit(df)\n",
        "\n",
        "# Display coefficients and summary\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALQ-_Q8f7HbJ",
        "outputId": "f93c0e4e-93b2-45e1-ef02-c02409056bd2"
      },
      "id": "ALQ-_Q8f7HbJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [-12.262057929180484,4.087352266486688]\n",
            "Intercept: 11.56891272665312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9066e04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9066e04",
        "outputId": "bb79db76-01b8-4f87-c0c4-c79525e85b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Centers: [array([12.5, 12.5]), array([3., 3.])]\n"
          ]
        }
      ],
      "source": [
        "# Practice: KMeans Clustering\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.linalg import Vectors # Import Vectors\n",
        "\n",
        "# Example dataset\n",
        "data = [(1, Vectors.dense([1.0, 1.0])), (2, Vectors.dense([5.0, 5.0])), (3, Vectors.dense([10.0, 10.0])), (4, Vectors.dense([15.0, 15.0]))]\n",
        "columns = ['ID', 'Features']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Train KMeans clustering model\n",
        "kmeans = KMeans(featuresCol='Features', k=2)\n",
        "model = kmeans.fit(df)\n",
        "\n",
        "# Show cluster centers\n",
        "centers = model.clusterCenters()\n",
        "print(f'Cluster Centers: {centers}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a60a8d7e",
      "metadata": {
        "id": "a60a8d7e"
      },
      "source": [
        "## Homework\n",
        "- Load a real-world dataset into Spark and prepare it for machine learning tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('unbalanced_twitter_btc_small.csv', engine='python')\n",
        "\n",
        "# Menghitung jumlah nilai yang hilang\n",
        "print(\"Jumlah nilai yang hilang di setiap kolom:\\n\")\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "0yDP3qGddMzh",
        "outputId": "b6813f53-3afd-4327-94e8-4fa46dda3f6b"
      },
      "id": "0yDP3qGddMzh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah nilai yang hilang di setiap kolom:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user_followers          0\n",
              "user_verified        3705\n",
              "date                 3705\n",
              "text                 3705\n",
              "hard_cleaned_text    4511\n",
              "soft_cleaned_text    4511\n",
              "vader_sentiment      5317\n",
              "afinn_sentiment      5317\n",
              "sentiment            5317\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>user_followers</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_verified</th>\n",
              "      <td>3705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <td>3705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>3705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hard_cleaned_text</th>\n",
              "      <td>4511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>soft_cleaned_text</th>\n",
              "      <td>4511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vader_sentiment</th>\n",
              "      <td>5317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>afinn_sentiment</th>\n",
              "      <td>5317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <td>5317</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Jumlah data sebelum pembersihan: {df.shape}\")\n",
        "\n",
        "# Menangani Missing Values\n",
        "df['user_verified'] = df['user_verified'].fillna(False)\n",
        "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "df['text'] = df['text'].fillna('')\n",
        "df['hard_cleaned_text'] = df['hard_cleaned_text'].fillna('')\n",
        "df['soft_cleaned_text'] = df['soft_cleaned_text'].fillna('')\n",
        "df['vader_sentiment'] = df['vader_sentiment'].fillna(df['vader_sentiment'].mean())\n",
        "df['afinn_sentiment'] = df['afinn_sentiment'].fillna(df['afinn_sentiment'].mean())\n",
        "df = df.dropna(subset=['sentiment'])\n",
        "\n",
        "# Normalisasi dataset\n",
        "df.loc[:, 'user_followers'] = pd.to_numeric(df['user_followers'], errors='coerce')\n",
        "\n",
        "# Tampilkan jumlah baris dan kolom setelah menangani missing values\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "print(f\"Jumlah data setelah pembersihan: {df.shape}\")\n",
        "\n",
        "# Menghitung jumlah nilai yang hilang\n",
        "print(\"Jumlah nilai yang hilang di setiap kolom:\")\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "iNHFSoLddPPS",
        "outputId": "3d2a0595-496f-44dc-dca3-011aa9b98551"
      },
      "id": "iNHFSoLddPPS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data sebelum pembersihan: (163440, 9)\n",
            "Jumlah data setelah pembersihan: (158123, 9)\n",
            "Jumlah nilai yang hilang di setiap kolom:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user_followers       0\n",
              "user_verified        0\n",
              "date                 0\n",
              "text                 0\n",
              "hard_cleaned_text    0\n",
              "soft_cleaned_text    0\n",
              "vader_sentiment      0\n",
              "afinn_sentiment      0\n",
              "sentiment            0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>user_followers</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_verified</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hard_cleaned_text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>soft_cleaned_text</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vader_sentiment</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>afinn_sentiment</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Build a classification model using Spark MLlib and evaluate its performance."
      ],
      "metadata": {
        "id": "tVkC6520Pn8Z"
      },
      "id": "tVkC6520Pn8Z"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "# Inisialisasi Spark session\n",
        "spark = SparkSession.builder.appName('SentimentAnalysis').getOrCreate()\n",
        "sdf = spark.createDataFrame(df) # Memuat dataset\n",
        "\n",
        "# Menambahkan kolom kategori sentimen berdasarkan kolom sentiment\n",
        "sdf = sdf.withColumn(\n",
        "      \"sentiment_category\",\n",
        "      when(col(\"sentiment\") > 0.05, \"positif\")\n",
        "      .when(col(\"sentiment\") < -0.05, \"negatif\")\n",
        "      .otherwise(\"netral\")\n",
        ")\n",
        "\n",
        "# Tampilkan hasil kategori sentimen untuk pengecekan\n",
        "print(\"Hasil pengkategorian sentimen:\")\n",
        "sdf.select(\"soft_cleaned_text\", \"sentiment\", \"sentiment_category\").show(5, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM0r_DLtdS_s",
        "outputId": "8a341553-5584-421a-ecf5-5a40a32ea78c"
      },
      "id": "OM0r_DLtdS_s",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil pengkategorian sentimen:\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------+------------------+------------------+\n",
            "|soft_cleaned_text                                                                                                                                |sentiment         |sentiment_category|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------+------------------+------------------+\n",
            "|Which bitcoin books should I think about reading next?                                                                                           |-0.023076923076923|netral            |\n",
            "|I appreciate the message, but not a fan of the religious references. Religion has nothing to do with Bitcoin.                                    |0.3372676923076922|positif           |\n",
            "|Ethereum price update: . ETH $1664.02 USD. Bitcoin 0.070428 BTC. Follow for recent ETH price updates. altcoin, cryptocurrency, crypto            |-0.023076923076923|netral            |\n",
            "|CoinDashboard v3.0 is here. Available on ios and Android. Bitcoin                                                                                |-0.023076923076923|netral            |\n",
            "|Bitcoin Short Term Fractal (4H) . In lower timeframe, BTC price action seems to be repeating itself while LMACD is reproducing the same sequence.|-0.141476923076923|negatif           |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------+------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Menyusun fitur dengan kolom sentiment\n",
        "assembler = VectorAssembler(inputCols=['sentiment'], outputCol='features')\n",
        "sdf = assembler.transform(sdf)\n",
        "\n",
        "# Mengubah kolom 'sentiment_category' menjadi label numerik\n",
        "# Sentiment categories: 'positif' -> 0, 'negatif' -> 1, 'netral' -> 2\n",
        "sdf = sdf.withColumn(\n",
        "      \"label\",\n",
        "      when(col(\"sentiment_category\") == \"positif\", 0)\n",
        "      .when(col(\"sentiment_category\") == \"negatif\", 1)\n",
        "      .otherwise(2)\n",
        ")"
      ],
      "metadata": {
        "id": "LAMsDi-JdVgI"
      },
      "id": "LAMsDi-JdVgI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membagi data menjadi train dan test\n",
        "train_data, test_data = sdf.randomSplit([0.8, 0.2], seed=1234)\n",
        "print(f\"Jumlah data Train: {train_data.count()}\")\n",
        "print(f\"Jumlah data Test: {test_data.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnPN6pOwdXZD",
        "outputId": "8494ab81-f294-45be-9a3c-4fae65961330"
      },
      "id": "ZnPN6pOwdXZD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data Train: 126645\n",
            "Jumlah data Test: 31478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model klasifikasi dengan Random Forest\n",
        "rf = RandomForestClassifier(featuresCol='features', labelCol='label', numTrees=100)\n",
        "\n",
        "# Melatih model\n",
        "rf_model = rf.fit(train_data)\n",
        "\n",
        "# Evaluasi model\n",
        "predictions = rf_model.transform(test_data)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f'Akurasi Model: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGerYLMDdZBJ",
        "outputId": "4367d961-74b4-4c46-a5bf-132611c12579"
      },
      "id": "kGerYLMDdZBJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi Model: 0.9797954126691658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Explore hyperparameter tuning using cross-validation."
      ],
      "metadata": {
        "id": "_EE45sO5Pkz2"
      },
      "id": "_EE45sO5Pkz2"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "paramGrid = ParamGridBuilder()\\\n",
        "    .addGrid(rf.maxDepth, [5, 10])\\\n",
        "    .addGrid(rf.numTrees, [50, 100])\\\n",
        "    .build()\n",
        "\n",
        "crossval = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3)\n",
        "cv_model = crossval.fit(train_data)\n",
        "\n",
        "# Evaluasi model dengan cross-validation\n",
        "cv_predictions = cv_model.transform(test_data)\n",
        "cv_accuracy = evaluator.evaluate(cv_predictions)\n",
        "print(f'Akurasi dengan Cross-Validation: {cv_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92-rfR2wdaqz",
        "outputId": "37159982-4fb8-4c39-84f7-f79fc0f0bc53"
      },
      "id": "92-rfR2wdaqz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi dengan Cross-Validation: 0.9797954126691658\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}